# 推荐系统

![img](https://pic2.zhimg.com/80/v2-b050168d77a3aaa2a028787641bba639_720w.jpg)

## 召回层

召回率 = TP/(TP+FN)

### 召回层的作用和意义

召回阶段负责从海量数据中快速筛选出部分数据，供后面排序阶段使用。本质上，召回和后面的粗排、精排、重排都属于排序，之所以分成召回阶段和后面3个排序阶段，**主要原因之一**是基于工程上的考虑。在精排阶段，一般会使用复杂的模型和特征，比如模型使用深层神经网络，特征filed上千个，如果精排对上百万的候选集排序，耗时肯定扛不住。因此加入召回过程，利用少量的特征和简单的模型或规则对候选集快速筛选，减少后面排序阶段的时间开销。**另外一个原因**是出于业务上的考虑，排序阶段主要考虑单一目标，比如ctr，而有时候我们希望给用户多展现热点新闻或者时效性数据，这时候可以多加两路召回。总结起来，召回和排序有如下特点：

- **召回层**：候选集规模大、模型和特征简单、速度快，尽量保证用户感兴趣数据多召回。
- **排序层**：候选集不大，目标是保证排序的精准，一般使用复杂和模型和特征。

### 召回层设计理念

+ 时间开销低
+ 兼顾用户的兴趣以及当下的热点

大多使用多路召回的方法

![img](https://pic2.zhimg.com/80/v2-a1fc300b4f0fa1bb739292b7b05be669_720w.jpg)

在设计召回层时，需要同时考虑召回率和计算速度，前面提到既要召回用户感兴趣数据，又要召回热点和时效性数据，如果一次同时召回，那么时间开销会是问题。这时候，一般考虑多路召回，上图显示了多路召回方法。

考虑召回的方式包含用户的兴趣、时下的热点新闻、地域热点新闻、协同过滤（根据与用户相似的用户的喜爱进行推荐）

![img](https://pic4.zhimg.com/80/v2-7ee3cbb82929d34022a633019713fc0b_720w.jpg)

### 召回算法

![img](https://pic4.zhimg.com/80/v2-7ee3cbb82929d34022a633019713fc0b_720w.jpg)

#### 传统召回方法

1. 基于协同过滤算法的找回算法

如基于用户相似性推荐的叫UserCF，基于物品相似度推荐的叫ItemCF

基本流程 以用户userCF

+ 构建共现矩阵，将用户评价转化为共现矩阵
+ 计算用户相似度
+ 相似用户兴趣推荐给当前用户

计算相似度的指标

(1) Jaccard距离

![[公式]](https://www.zhihu.com/equation?tex=sim%5Cleft%28+%5Ctextbf%7Bx%7D%2C%5Ctextbf%7By%7D+%5Cright%29%3D%5Cfrac%7B%5Cleft%7C+%5Ctextbf%7Bx%7D%5Ccap+%5Ctextbf%7By%7D+%5Cright%7C%7D%7B%5Cleft%7C+%5Ctextbf%7Bx%7D%5Ccup%5Ctextbf%7By%7D+%5Cright%7C%7D%5Ctag2)

(2) 欧氏距离

![[公式]](https://www.zhihu.com/equation?tex=d%5Cleft%28+%5Ctextbf%7Bx%7D%2C+%5Ctextbf%7By%7D%5Cright%29%3D%5Csqrt%7B%5Csum%5Cnolimits_%7Bi%7D%5Cleft%28+x_i-y_i+%5Cright%29%5E2%7D%5Ctag3)

![[公式]](https://www.zhihu.com/equation?tex=sim%5Cleft%28+%5Ctextbf%7Bx%7D%2C%5Ctextbf%7By%7D+%5Cright%29%3D%5Cfrac%7B1%7D%7B1%2Bd%5Cleft%28+%5Ctextbf%7Bx%7D%2C%5Ctextbf%7By%7D+%5Cright%29%7D%5Ctag4)

(3) 皮尔逊系数

![[公式]](https://www.zhihu.com/equation?tex=sim%5Cleft%28+%5Ctextbf%7Bx%7D%2C+%5Ctextbf%7By%7D%5Cright%29%3D%5Cfrac%7B%5Csum%5Cnolimits_%7Bi%7D%5Cleft%28+x_i-%5Coverline%7B%5Ctextbf%7Bx%7D%7D+%5Cright%29%5Cleft%28+y_i-%5Coverline%7B%5Ctextbf%7By%7D%7D+%5Cright%29%7D%7B%5Csqrt%7B%5Csum%5Cnolimits_%7Bi%7D%5Cleft%28+x_i-%5Coverline%7B%5Ctextbf%7Bx%7D%7D+%5Cright%29%5E2%7D%5Csqrt%7B%5Csum%5Cnolimits_%7Bi%7D%5Cleft%28+y_i-%5Coverline%7B%5Ctextbf%7By%7D%7D+%5Cright%29%5E2%7D%7D%5Ctag5)

(4) 余弦相似度

![[公式]](https://www.zhihu.com/equation?tex=sim%5Cleft%28+%5Ctextbf%7Bx%7D%2C%5Ctextbf%7By%7D+%5Cright%29%3D%5Cfrac%7B%5Ctextbf%7Bx%7D+%5Ccdot+%5Ctextbf%7By%7D%7D%7B%5Cleft+%5C%7C+%5Ctextbf%7Bx%7D%5Cright+%5C%7C+%5Ctimes+%5Cleft+%5C%7C+%5Ctextbf%7By%7D++%5Cright+%5C%7C%7D%3D%5Cfrac%7B%5Csum%5Cnolimits_%7Bi%7Dx_iy_i%7D%7B%5Csqrt%7B%5Csum%5Cnolimits_%7Bi%7Dx_i%5E2%7D%5Csqrt%7B%5Csum%5Cnolimits_%7Bi%7Dy_i%5E2%7D%7D%5Ctag6)

(5)  Tanimoto系数

![[公式]](https://www.zhihu.com/equation?tex=sim%5Cleft%28+%5Ctextbf%7Bx%7D%2C%5Ctextbf%7By%7D+%5Cright%29%3D%5Cfrac%7B%5Ctextbf%7Bx%7D+%5Ccdot+%5Ctextbf%7By%7D%7D%7B%5Cleft+%5C%7C+%5Ctextbf%7Bx%7D%5Cright+%5C%7C%5E2%2B+%5Cleft+%5C%7C+%5Ctextbf%7By%7D++%5Cright+%5C%7C%5E2-%5Ctextbf%7Bx%7D+%5Ccdot+%5Ctextbf%7By%7D%7D%3D%5Cfrac%7B%5Csum%5Cnolimits_%7Bi%7Dx_iy_i%7D%7B%5Csqrt%7B%5Csum%5Cnolimits_%7Bi%7Dx_i%5E2%7D%2B%5Csqrt%7B%5Csum%5Cnolimits_%7Bi%7Dy_i%5E2%7D-%5Csum%5Cnolimits_%7Bi%7Dx_iy_i%7D%5Ctag7)

UserCF缺陷

（1）**计算和存储开销**。UserCF需要计算和存储用户之间的相似度，在互联网企业，用户规模一般都比较庞大，导致计算和存储的开销非常大。

（2）**稀疏用户效果不佳**。用户的历史行为一般都是比较稀疏的，比如电商场景，有些用户可能一个月就几次购买行为，对于这些用户计算相似度一般都不太准确，因此UserCF不太适合用户行为稀疏的场景。

由于UserCF工程和效果上的缺陷，大多数互联网企业都选择ItemCF。ItemCF是**基于物品相似度进行推荐**的协同过滤算法。具体讲，通过计算Item之间的相似度，得到Item相似度矩阵，然后找到用户历史正反馈物品的相似物品进行排序和推荐，ItemCF的步骤总结如下：

（1）构建共现矩阵。根据用户的行为，构建以用户为行坐标，物品为纵坐标的共现矩阵。

（2）构建物品相似度矩阵。根据共现矩阵计算两两物品之间的相似度，得到物品相似度矩阵。

（3）获取Top ![[公式]](https://www.zhihu.com/equation?tex=n) 相似物品。根据用户历史正反馈物品，找出最相似的 ![[公式]](https://www.zhihu.com/equation?tex=n) 个物品。

（4）计算用户对Top ![[公式]](https://www.zhihu.com/equation?tex=n) 物品的喜好度。用户对物品的喜好度定义为：当前物品和用户历史物品评分的加权和，加权系数是前面计算的物品相似度。计算方法如下所示。

![[公式]](https://www.zhihu.com/equation?tex=r_%7Bu%2Cp%7D%3D%5Csum%5Cnolimits_%7Bi%7Dw_%7Bp%2Ci%7D%5Ccdot+r_%7Bu%2Ci%7D%5Ctag%7B9%7D)

其中 ![[公式]](https://www.zhihu.com/equation?tex=r_%7Bu%2Cp%7D) 表示预估的用户 ![[公式]](https://www.zhihu.com/equation?tex=u) 对物品 ![[公式]](https://www.zhihu.com/equation?tex=p) 的喜好度， ![[公式]](https://www.zhihu.com/equation?tex=w_%7Bp%2Ci%7D) 是加权系数，表示目标物品 ![[公式]](https://www.zhihu.com/equation?tex=p) 和Top ![[公式]](https://www.zhihu.com/equation?tex=n) 集合中物品 ![[公式]](https://www.zhihu.com/equation?tex=i) 的相似度， ![[公式]](https://www.zhihu.com/equation?tex=r_%7Bu%2Ci%7D) 表示用户历史对物品 ![[公式]](https://www.zhihu.com/equation?tex=i) 的评分。

（5）按喜好度生成排序结果。

和UserCF相比，由于物品规模一般远远小于用户数，因此ItemCF的计算和存储开销都比UserCF小得多。除了技术实现上的区别，UserCF和ItemCF的应用场景也有所不同。总结为下面两点。

（1）UserCF更适合新闻推荐场景。在新闻推荐场景中，新闻的兴趣点一般比较分散，比如虎嗅的新闻一般受众群体是从事IT的人，而UserCF可以快速找到都是从事IT的人群，然后把虎嗅的新闻推荐给自己。

（2）ItemCF更适合电商或视频推荐场景。在电商和视频推荐场景中，都有一个共同点，用户的兴趣比较稳定。比如在电商场景，ItemCF可以推荐和兴趣点相似的商品，比如以前经常购买球鞋的人，可以推荐球衣球裤。





基于矩阵分解的方法

基于SVD的改进版

SVD应用在推荐系统中，用户矩阵表示为 ![[公式]](https://www.zhihu.com/equation?tex=%5Ctextbf%7BU%7D_%7Bm%5Ctimes+k%7D)，物品矩阵表示为 ![[公式]](https://www.zhihu.com/equation?tex=%5Ctextbf%7BV%7D_%7Bn%5Ctimes+k%7D) 。这样就可以计算用户和物品的相似度，但是在工程上会有问题，奇异值分解的计算复杂度达到了 ![[公式]](https://www.zhihu.com/equation?tex=O%5Cleft%28+mn%5E2+%5Cright%29) ，对于物品上百万的互联网行业是无法接受的。另外，SVD对于稀疏的共现矩阵也不友好，需要人为填充缺失值，而互联行业用户行为大多是比较稀疏的。



#### 传统召回方法总结

传统召回算法有其**简单、可解释性强**的特点，但是也有自身的局限性。协同过滤和矩阵分解都**没有加入用户、物品和上下文相关的特征**，也没有考虑用户行为之间的相关性。随着embedding技术的发展，召回技术开始朝着模型化embedding的方向演化。





#### Embedding召回

所谓embedding其实就是用一个低维稠密的向量表示一个对象，这里的对象可以是一个词、一个商品，也可以是一篇新闻、一部电影，等等。直观上看embedding相当于是对one-hot做了平滑。



one-hot表示一个对象时，往往高维稀疏，以词向量为例，牛津词典英语单词大概有10万个左右，因此one-hot就是10万维。经过某个语言模型后，我们可以把它转化为低维的稠密向量，这样就可以很方便的计算词之间的相似度，这个语言模型就是embedding的产生过程，比如接下来要讲的Word2Vec。图6显示了词向量经过embedding化后，man和king之间具有更高的相似度。

![img](https://pic3.zhimg.com/80/v2-43566071cbe4aecb14dea3d5cc9392a6_720w.jpg)图6 词向量embedding化

图6显示了embedding具有很好的表达能力，但是embedding究竟是怎么产生的，前面的SVD已经隐约有了embedding的影子。图7显示了embedding的产生过程，可以看出，**embedding是神经网络的中间产物**，神经网络的隐藏层权重便是最终生成的embedding，生成embedding表后，可以通过查表的方式获取具体的embedding向量。

![img](https://pic1.zhimg.com/80/v2-b63a068d913cd3212fe341ae42c034b0_720w.jpg)图7 embedding产生过程



i2i召回框架   (item2item)

在介绍完embedding的概念后，这部分介绍下基于embedding的召回框架，主要分为i2i召回和u2i召回。**i2i召回是指我们可以得到item embedding**，但是模型**没有直接得到user embedding**。**u2i是指模型同时得到了user embedding和item embedding**。先介绍下第一种情况，即i2i召回框架，如图9所示。离线根据用户历史行为训练召回模型，输出item embedding，存储到数据库中，线上用户请求，根据用户历史行为，从数据库从查找对应的embedding，然后检索相似度最高的n个item，最后将Top n召回结果返回给后面的排序模块。

![img](https://pic4.zhimg.com/80/v2-d1383f4cc37930bb3b05d5cf940b9eeb_720w.jpg)



